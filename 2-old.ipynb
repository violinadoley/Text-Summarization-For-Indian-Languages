{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9624351,"sourceType":"datasetVersion","datasetId":5874665}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import GradientBoostingClassifier, VotingClassifier, RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, StackingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression, ElasticNet\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cb\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.over_sampling import SMOTE\n\n# Load the dataset\nfile_path = '/kaggle/input/abcdefghi/Seed dataset.csv'\ndata = pd.read_csv(file_path)\n\n# Splitting the input (features) and output (label)\nX = data['Comments'] + ' ' + data['Surrounding Code Context']  # Combining both input columns\ny = data['Class']","metadata":{"execution":{"iopub.status.busy":"2024-10-14T16:01:15.180002Z","iopub.execute_input":"2024-10-14T16:01:15.180334Z","iopub.status.idle":"2024-10-14T16:01:21.960907Z","shell.execute_reply.started":"2024-10-14T16:01:15.180301Z","shell.execute_reply":"2024-10-14T16:01:21.959883Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\n\n# Convert the categorical target labels (useful/not useful) to numerical values\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)  # Converts \"Useful\" to 1 and \"Not Useful\" to 0\n\n# Convert text data into numerical feature vectors using TF-IDF with n-grams\nvectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))  # Using unigrams and bigrams\nX_vec = vectorizer.fit_transform(X)\n\n# Handle class imbalance with SMOTE (oversampling the minority class)\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X_vec, y_encoded)\n\n# Split the dataset into training and testing sets (80:20)\nX_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n\n# Function to calculate and print Precision, Recall, and F1-Score\ndef evaluate_model(model, X_test, y_test, model_name):\n    y_pred = model.predict(X_test)\n    precision = precision_score(y_test, y_pred, average='binary')\n    recall = recall_score(y_test, y_pred, average='binary')\n    f1 = f1_score(y_test, y_pred, average='binary')\n    \n    print(f\"\\n{model_name} Model:\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T16:01:21.962677Z","iopub.execute_input":"2024-10-14T16:01:21.963024Z","iopub.status.idle":"2024-10-14T16:01:27.227590Z","shell.execute_reply.started":"2024-10-14T16:01:21.962989Z","shell.execute_reply":"2024-10-14T16:01:27.226666Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# 1. CatBoost Classifier (Fast gradient boosting)\ncat_model = cb.CatBoostClassifier(iterations=500, depth=6, learning_rate=0.1, verbose=0)\ncat_model.fit(X_train, y_train)\nevaluate_model(cat_model, X_test, y_test, \"CatBoost\")\n\n# 2. ExtraTrees Classifier (Randomized trees, similar to RandomForest but with more variance reduction)\nextra_trees = ExtraTreesClassifier(n_estimators=200, max_depth=10, min_samples_split=5, random_state=42)\nextra_trees.fit(X_train, y_train)\nevaluate_model(extra_trees, X_test, y_test, \"ExtraTrees\")\n\n# 3. ElasticNet (Combination of Lasso and Ridge regularization)\nelastic_net = ElasticNet(alpha=0.01, l1_ratio=0.7)\nelastic_net.fit(X_train, y_train)\ny_pred_elastic = elastic_net.predict(X_test)\n# ElasticNet does not give classification outputs directly, so let's use a threshold to convert to classes\ny_pred_elastic_class = [1 if pred > 0.5 else 0 for pred in y_pred_elastic]\nprecision = precision_score(y_test, y_pred_elastic_class, average='binary')\nrecall = recall_score(y_test, y_pred_elastic_class, average='binary')\nf1 = f1_score(y_test, y_pred_elastic_class, average='binary')\nprint(f\"\\nElasticNet Model:\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\\nF1-Score: {f1:.4f}\")\n\n# 4. Stacking Classifier (Combining multiple models in a meta-learner)\nestimators = [('rf', RandomForestClassifier(n_estimators=100)),\n              ('gb', GradientBoostingClassifier(n_estimators=100))]\nstacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\nstacking.fit(X_train, y_train)\nevaluate_model(stacking, X_test, y_test, \"Stacking Classifier\")\n\n# 5. Neural Network (Multi-Layer Perceptron - MLP)\nmlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, solver='adam', learning_rate='adaptive', random_state=42)\nmlp.fit(X_train, y_train)\nevaluate_model(mlp, X_test, y_test, \"Neural Network (MLP)\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-14T16:01:27.228942Z","iopub.execute_input":"2024-10-14T16:01:27.229568Z","iopub.status.idle":"2024-10-14T16:06:06.370271Z","shell.execute_reply.started":"2024-10-14T16:01:27.229525Z","shell.execute_reply":"2024-10-14T16:06:06.368906Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\nCatBoost Model:\nPrecision: 0.8310\nRecall: 0.8082\nF1-Score: 0.8194\n\nExtraTrees Model:\nPrecision: 0.8121\nRecall: 0.6723\nF1-Score: 0.7356\n\nElasticNet Model:\nPrecision: 0.7457\nRecall: 0.5009\nF1-Score: 0.5993\n\nStacking Classifier Model:\nPrecision: 0.8117\nRecall: 0.8366\nF1-Score: 0.8239\n\nNeural Network (MLP) Model:\nPrecision: 0.8365\nRecall: 0.7910\nF1-Score: 0.8131\n","output_type":"stream"}]}]}